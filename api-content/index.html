{"posts":[{"title":"kafka集群搭建","content":"kafka+zookper 一. 环境准备 关闭selinux，关闭防火墙 kafka 版本: kafka_2.11-2.1.0 zookpeeper版本: 3.4.12 jdk: 1.8 ip 角色 系统 172.10.10.226 zookeeper+kafka redhat7.3 172.10.10.225 zookeeper+kafka redhat7.3 172.10.10.224 zookeeper+kafka redhat7.3 二. zookeeper集群搭建 2.1 jdk 安装 也可自己下载安装,这里用的yum JDK下载地址：http://www.oracle.com/technetwork/java/javase/downloads/index.html rpm -ivh jdk-8u101-linux-x64.rpm yum install java-1.8.0 2.2 zookeeper安装 Zookeeper链接：http://zookeeper.apache.org/ wget http://mirrors.cnnic.cn/apache/zookeeper/zookeeper-3.4.12/zookeeper-3.4.12.tar.gz -P /mnt tar zxvf zookeeper-3.4.12.tar.gz -C /mnt cd /mnt &amp;&amp; mv zookeeper-3.4.12 zookeeper cd zookeeper cp conf/zoo_sample.cfg conf/zoo.cfg #把zookeeper加入到环境变量 echo -e &quot;# append zk_env\\nexport PATH=$PATH:/opt/zookeeper/bin&quot; &gt;&gt; /etc/profile 2.3 zookeeper集群配置 2.3.1 zookeeper配置文件修改.在zookeeper的conf目录创建 tickTime=2000 initLimit=10 syncLimit=5 dataLogDir=/mnt/zookeeper/logs dataDir=/mnt/zookeeper/data clientPort=2181 #autopurge.snapRetainCount=500 #autopurge.purgeInterval=24 server.1= 172.10.10.226:2888:3888 #server.1 中的1表示的该node的id，要和后面myid文件中保持一致 server.2= 172.10.10.225:2888:3888 server.3= 172.10.10.224:2888:3888#######参数说明 tickTime这个时间是作为zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔,也就是说每个tickTime时间就会发送一个心跳。 initLimit这个配置项是用来配置zookeeper接受客户端（这里所说的客户端不是用户连接zookeeper服务器的客户端,而是zookeeper服务器集群中连接到leader的follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。 当已经超过10个心跳的时间（也就是tickTime）长度后 zookeeper 服务器还没有收到客户端的返回信息,那么表明这个客户端连接失败。总的时间长度就是 10*2000=20秒。 syncLimit这个配置项标识leader与follower之间发送消息,请求和应答时间长度,最长不能超过多少个tickTime的时间长度,总的时间长度就是5*2000=10秒。 dataDir顾名思义就是zookeeper保存数据的目录,默认情况下zookeeper将写数据的日志文件也保存在这个目录里； clientPort这个端口就是客户端连接Zookeeper服务器的端口,Zookeeper会监听这个端口接受客户端的访问请求； server.A=B:C:D中的A是一个数字,表示这个是第几号服务器,B是这个服务器的IP地址，C第一个端口用来集群成员的信息交换,表示这个服务器与集群中的leader服务器交换信息的端口，D是在leader挂掉时专门用来进行选举leader所用的端口。 \\#创建相关目录，三台节点都需要 mkdir -p /mnt/zookeeper/{logs,data} \\#其余zookeeper节点安装完成之后，同步配置文件zoo.cfg。 2.3.2 创建serverid表识 除了修改zoo.cfg配置文件外,zookeeper集群模式下还要配置一个myid文件,这个文件需要放在dataDir目录下。 这个文件里面有一个数据就是A的值（该A就是zoo.cfg文件中server.A=B:C:D中的A）,在zoo.cfg文件中配置的dataDir路径中创建myid文件。 #在172.10.10.226服务器上面创建myid文件，并设置值为1，同时与zoo.cfg文件里面的server.1保持一致，如下 echo &quot;1&quot; &gt; /mnt/zookeeper/data/myid 其它2台id分别为 2 ，3 2.4. 启动每个服务器上的集群节点 /mnt/zookeeper/bin/zkServer.sh start #启动 /mnt/zookeeper/bin/zkServer.sh status #查看 bin/zkCli.sh -server 172.10.10.225:2181 #模拟客户端连接 Zookeeper集群搭建完毕之后，可以通过客户端脚本连接到zookeeper集群上面，对客户端来说，zookeeper集群是一个整体，连接到zookeeper集群实际上感觉在独享整个集群的服务。 三. kafka集群搭建 1. 每台服务器上下载解压kafka. 下载地址： http://kafka.apache.org/downloads 2. 配置conf目录下的server.properties [root@r0 kafka_2.11-2.1.0]# grep -E -v &quot;^#|^$&quot; config/server.properties broker.id=0 ###集群中唯一 listeners=PLAINTEXT://172.10.10.226:9092 ####本地ip:端口 num.network.threads=3 num.io.threads=8 socket.send.buffer.bytes=102400 socket.receive.buffer.bytes=102400 socket.request.max.bytes=104857600 log.dirs=/tmp/kafka-logs num.partitions=3 #### 一个topic的partition个数 num.recovery.threads.per.data.dir=1 offsets.topic.replication.factor=1 transaction.state.log.replication.factor=1 transaction.state.log.min.isr=1 replication.factor=2 ##### 每个partition的副本 log.retention.hours=168 log.segment.bytes=1073741824 log.retention.check.interval.ms=300000 zookeeper.connect=172.10.10.226:2181,172.10.10.225:2181,172.10.10.224:2181 ####zookeeper集群. zookeeper.connection.timeout.ms=6000 group.initial.rebalance.delay.ms=0delete.topic.enable=true ########可删除topic 将上述配置文件复制到另外2台服务器，并修改每个节点对应的 server.properties 文件的 broker.id和listenrs 3. 启动服务 bin/kafka-server-start.sh config/server.properties &amp; 4. kafka+zookeeper测试 创建topic bin/kafka-topics.sh --create --zookeeper 172.10.10.226:2181,172.10.10.225:2182,172.10.10.224:2183 --replication-factor 2 --partitions 3 --topic test 显示topic bin/kafka-topics.sh --describe --zookeeper 172.10.10.226:2181,172.10.10.225:2182,172.10.10.224:2183 --topic test OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N Topic:test PartitionCount:3 ReplicationFactor:2 Configs: Topic: test Partition: 0 Leader: 0 Replicas: 0,1 Isr: 0,1 Topic: test Partition: 1 Leader: 1 Replicas: 1,2 Isr: 1,2 Topic: test Partition: 2 Leader: 2 Replicas: 2,0 Isr: 2,0 创建 producer(生产者): [root@r0 kafka_2.11-2.1.0]# bin/kafka-console-producer.sh --broker-list 172.10.10.226:9092 -topic test OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N &gt; &gt;&gt;1111 &gt;2222 &gt;333 创建 consumer(消费者): [root@r2 kafka_2.11-2.1.0]# bin/kafka-console-consumer.sh --bootstrap-server 172.10.10.226:9092,172.10.10.225:9092,172.10.10.224:9092 --topic test --from-beginning OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N message 3 message 6 333333333 5555555555 5 5 #问题，发现为啥顺序不对，生产者的输入顺序和消费者的读取顺序不一致. 5. 关闭集群 # 删除topic bin/kafka-topics.sh --delete --zookeeper 172.10.10.226:2181,172.10.10.225:2181,172.10.10.224:2181 --topic test # 关闭kafka ,3台都执行 [root@worker2 kafka_2.12-1.1.0]$ bin/kafka-server-stop.sh conf/server.properties [root@worker2 kafka_2.12-1.1.0]$ bin/kafka-server-stop.sh conf/server.properties [root@worker2 kafka_2.12-1.1.0]$ bin/kafka-server-stop.sh conf/server.properties # 关闭zookeeper ,3台都执行 [root@master zookeeper-3.4.11]$ bin/zkServer.sh stop conf/zoo.cfg [root@worker1 zookeeper-3.4.11]$ bin/zkServer.shstop conf/zoo.cfg [root@worker2 zookeeper-3.4.11]$ bin/zkServer.shstop conf/zoo.cfg ","link":"https://yanhaha111.github.io/post/kafka-ji-qun-da-jian/"},{"title":"percona模版监控mysql","content":"https://www.qstack.com.cn/archives/213.html 1.安装php环境 percona需要php环境 [root@m01 /data/soft]# yum install php php-mysql -y 2.下载软件 注意，安装完成后会有提示模版的路径位置 [root@m01 ~]# cd /data/soft/ [root@m01 /data/soft]# wget https://www.percona.com/downloads/percona-monitoring-plugins/percona-monitoring-plugins-1.1.8/binary/redhat/7/x86_64/percona-zabbix-templates-1.1.8-1.noarch.rpm [root@m01 /data/soft]# rpm -ivh percona-zabbix-templates-1.1.8-1.noarch.rpm 警告：percona-zabbix-templates-1.1.8-1.noarch.rpm: 头V4 DSA/SHA1 Signature, 密钥 ID cd2efd2a: NOKEY 准备中... ################################# [100%] 正在升级/安装... 1:percona-zabbix-templates-1.1.8-1 ################################# [100%] Scripts are installed to /var/lib/zabbix/percona/scripts Templates are installed to /var/lib/zabbix/percona/templates 3.查看目录 进入安装目录会发现有2个目录，一个是脚本目录，一个是模版目录 [root@m01 ~]# cd /var/lib/zabbix/percona/ [root@m01 /var/lib/zabbix/percona]# tree . ├── scripts │ ├── get_mysql_stats_wrapper.sh │ └── ss_get_mysql_stats.php └── templates ├── userparameter_percona_mysql.conf └── zabbix_agent_template_percona_mysql_server_ht_2.0.9-sver1.1.8.xml 其中脚本目录里有2个脚本，用来获取数据库信息 [root@m01 /var/lib/zabbix/percona]# cd scripts/ [root@m01 /var/lib/zabbix/percona/scripts]# ls get_mysql_stats_wrapper.sh ss_get_mysql_stats.php 4.修改get_mysql_stats_wrapper.sh 修改get_mysql_stats_wrapper数据库登陆信息 第19行添加mysql账号密码 [root@m01 v]# sed -n '19p' get_mysql_stats_wrapper.sh RES=`HOME=~zabbix mysql -uroot -p123123 -e 'SHOW SLAVE STATUS\\G' | egrep '(Slave_IO_Running|Slave_SQL_Running):' | awk -F: '{print $2}' | tr '\\n' 5.修改ss_get_mysql_stats.php [root@m01 /var/lib/zabbix/percona/scripts]# sed -n '30,31p' ss_get_mysql_stats.php $mysql_user = 'root'; $mysql_pass = '123123'; 6.复制自定义监控项配置文件到zabbix目录 [root@m01 ~]# cd /var/lib/zabbix/percona/templates/ [root@m01 /var/lib/zabbix/percona/templates]# cp userparameter_percona_mysql.conf /etc/zabbix/zabbix_agentd.d/ [root@m01 /var/lib/zabbix/percona/templates]# cd /etc/zabbix/zabbix_agentd.d/ [root@m01 /etc/zabbix/zabbix_agentd.d]# ls userparameter_mysql.conf userparameter_percona_mysql.conf 7.重启agent [root@m01 ~]# systemctl restart zabbix-agent 8.测试key [root@m01 ~]# zabbix_get -s 192.168.5.50 -k MySQL.Sort-scan 24 9.导入模版 官方自带的模版有点问题，需要先装在2.x版本然后导出来，这里使用网友已经修改好的模版上传 http://pan.baidu.com/s/1pL1wDYj 10.主机链接模版 xx.报错解决 查看监控发现没有数据显示不支持类型 查看zabbix-server发现因为tmp的文件没有权限，因为刚才手动执行了脚本，所以文件属性是root，将文件删除后由zabbix自己创建解决问题 报错日志如下： 2846:20190811:202708.785 item &quot;Zabbix server:MySQL.State-init&quot; became not supported: Value &quot;rm: 无法删除&quot;/tmp/localhost-mysql_cacti_stats.txt&quot;: 不允许的操作 0&quot; of type &quot;string&quot; is not suitable for value type &quot;Numeric (float)&quot; 2843:20190811:202709.787 item &quot;Zabbix server:MySQL.State-locked&quot; became not supported: Value &quot;rm: 无法删除&quot;/tmp/localhost-mysql_cacti_stats.txt&quot;: 不允许的操作 0&quot; of type &quot;string&quot; is not suitable for value type &quot;Numeric (float)&quot; 2844:20190811:202710.788 item &quot;Zabbix server:MySQL.State-login&quot; became not supported: Value &quot;rm: 无法删除&quot;/tmp/localhost-mysql_cacti_stats.txt&quot;: 不允许的操作 0&quot; of type &quot;string&quot; is not suitable for value type &quot;Numeric (float)&quot; ","link":"https://yanhaha111.github.io/post/percona-mo-ban-jian-kong-mysql/"}]}